{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1891014/672654799.py:35: UserWarning: Argument(s) 'glare_coefficient' are not valid for transform RandomSunFlare\n",
      "  RandomSunFlare(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 1335 entries from label file.\n",
      "First 3 entries: [{'filename': '000000_0.png', 'label': 'Pedestrian'}, {'filename': '000006_0.png', 'label': 'Car'}, {'filename': '000008_2.png', 'label': 'Car'}]\n",
      "Applying fog augmentation…\n",
      "Applying rain augmentation…\n",
      "Applying sun_flare augmentation…\n",
      "Applying blur augmentation…\n",
      "Applying snow augmentation…\n",
      "Applying grayscale augmentation…\n",
      "All done—check the “augmented” subfolders for fog, rain, sun_flare, blur, and snow.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    RandomFog,\n",
    "    RandomRain,\n",
    "    RandomSunFlare,\n",
    "    Blur,\n",
    "    RandomSnow,\n",
    ")\n",
    "json_path = Path(\"test_labels.json\")\n",
    "input_dir = Path(\"test\")           \n",
    "min_width = 150\n",
    "min_height = 150\n",
    "augmentations = {\n",
    "    \"fog\": Compose([\n",
    "        RandomFog(\n",
    "            alpha_coef=0.2,      \n",
    "            p=1.0\n",
    "        )\n",
    "    ]),\n",
    "\n",
    "    \"rain\": Compose([\n",
    "        RandomRain(\n",
    "            drop_color=[200, 200, 200],\n",
    "            blur_value=15,          \n",
    "            brightness_coefficient=1.0,  \n",
    "            rain_type=\"heavy\",      #\n",
    "            p=1.0\n",
    "        )\n",
    "    ]),\n",
    "\n",
    "    \"sun_flare\": Compose([\n",
    "        RandomSunFlare(\n",
    "            flare_roi=[0.0, 0.0, 1.0, 0.6], \n",
    "            src_radius=350,               \n",
    "            src_color=[255, 255, 255],           \n",
    "            glare_coefficient=0.5,           \n",
    "            p=1.0\n",
    "        )\n",
    "    ]),\n",
    "\n",
    "    \"blur\": Compose([\n",
    "        Blur(\n",
    "            blur_limit=(21, 21), \n",
    "            p=1.0\n",
    "        )\n",
    "    ]),\n",
    "\n",
    "    \"snow\": Compose([\n",
    "        RandomSnow(\n",
    "            brightness_coeff=3.0,  \n",
    "            p=1.0\n",
    "        )\n",
    "    ]),\n",
    "    \"grayscale\": Compose([ToGray(p=1.0)]),\n",
    "}\n",
    "with open(json_path, \"r\") as f:\n",
    "    label_dict = json.load(f)\n",
    "data = []\n",
    "for filename, label in label_dict.items():\n",
    "    filename = filename.strip()\n",
    "    label = label.strip()\n",
    "    data.append({\"filename\": filename, \"label\": label})\n",
    "\n",
    "print(f\"Parsed {len(data)} entries from label file.\")\n",
    "print(\"First 3 entries:\", data[:3])\n",
    "\n",
    "for aug_name, aug_pipeline in augmentations.items():\n",
    "    print(f\"Applying {aug_name} augmentation…\")\n",
    "    output_dir = Path(aug_name)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for entry in data:\n",
    "        img_path = input_dir / entry[\"filename\"]\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            print(f\"Warning: could not read {img_path}\")\n",
    "            continue\n",
    "        h, w = img.shape[:2]\n",
    "        if h < min_height or w < min_width:\n",
    "            # skip super small images\n",
    "            continue\n",
    "        augmented_img = aug_pipeline(image=img)[\"image\"]\n",
    "        save_path = output_dir / entry[\"filename\"]\n",
    "        cv2.imwrite(str(save_path), augmented_img)\n",
    "\n",
    "print(\"All done—check the “augmented” subfolders for fog, rain, sun_flare, blur, and snow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dice/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dice/anaconda3/envs/pytorch_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "def load_model():\n",
    "    model = /path/to/your/model.pth  \n",
    "    model.eval()\n",
    "    return model\n",
    "model = load_model()\n",
    "ttt_model = load_model()  \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "idx_to_label = {\n",
    "    207: \"Golden Retriever\",\n",
    "    281: \"Tabby Cat\",\n",
    "    282: \"Tiger Cat\",\n",
    "    409: \"Orange\",\n",
    "    555: \"Violin\"\n",
    "}\n",
    "\n",
    "def infer(img: Image.Image):\n",
    "    x = transform(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        out1 = model(x)\n",
    "        out2 = ttt_model(x) \n",
    "    pred1 = torch.argmax(out1, dim=1).item()\n",
    "    pred2 = torch.argmax(out2, dim=1).item()\n",
    "\n",
    "    label1 = idx_to_label.get(pred1, f\"Class {pred1}\")\n",
    "    label2 = idx_to_label.get(pred2, f\"Class {pred2} (TTT)\")\n",
    "\n",
    "    return label1, label2\n",
    "\n",
    "gr.Interface(\n",
    "    fn=infer,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=[\"text\", \"text\"],\n",
    "    title=\"Test-Time Training Demo\",\n",
    "    description=\"Upload an image and see how TTT improves predictions (simulated)\"\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
