{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b39310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define consistent scene class mapping\n",
    "SCENE_LABELS = ['rider', 'bus', 'person', 'train', 'traffic sign', 'car', 'bike', 'traffic light', 'motor', 'truck']\n",
    "SCENE2ID = {k: i for i, k in enumerate(SCENE_LABELS)}\n",
    "ID2SCENE = {i: k for i, k in enumerate(SCENE_LABELS)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4134e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_BDD(image_dir, label_dir, save_path, input_size=224):\n",
    "    \"\"\"\n",
    "    Prepares the BDD dataset by extracting images and labels, cropping them based on annotations,\n",
    "    and saving the processed dataset to the specified path.\n",
    "    \"\"\"\n",
    "    assert os.path.exists(image_dir), f\"Image directory {image_dir} does not exist.\"\n",
    "    assert os.path.exists(label_dir), f\"Label directory {label_dir} does not exist.\"\n",
    "    print(f\"Loading dataset images from {image_dir} and labels from {label_dir}...\")\n",
    "    # Finding the mean and std for normalization\n",
    "    vals = [[] for _ in range(3)]  # RGB channels\n",
    "    samples = []\n",
    "    class_names = set()\n",
    "\n",
    "    for fname in tqdm(os.listdir(image_dir)):\n",
    "        if fname.endswith('.jpg') or fname.endswith('.png'):\n",
    "            img_path = os.path.join(image_dir, fname)\n",
    "            image = Image.open(img_path)\n",
    "            # image.save(f\"original_{fname}.jpg\")\n",
    "\n",
    "            for channel in range(3):\n",
    "                vals[channel].extend(list(image.getdata(band=channel)))\n",
    "            \n",
    "            label_path = os.path.join(label_dir, fname + \".json\")\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    count = 0\n",
    "                    for obj in data.get(\"objects\", []):\n",
    "                        if obj[\"geometryType\"] != \"rectangle\" or obj[\"classTitle\"] not in SCENE_LABELS:\n",
    "                            continue\n",
    "\n",
    "                        class_name = obj[\"classTitle\"]\n",
    "                        x1, y1 = obj[\"points\"][\"exterior\"][0]\n",
    "                        x2, y2 = obj[\"points\"][\"exterior\"][1]\n",
    "\n",
    "                        # Compute full rectangle corners\n",
    "                        x_min, y_min = min(x1, x2), min(y1, y2)\n",
    "                        x_max, y_max = max(x1, x2), max(y1, y2)\n",
    "\n",
    "                        if x_max - x_min < input_size // 2 or y_max - y_min < input_size // 2:\n",
    "                            continue\n",
    "                        # Crop\n",
    "                        crop = image.crop((x_min, y_min, x_max, y_max))\n",
    "                        # print(crop.size)\n",
    "                        # crop.save(f\"{count}_{fname}\")\n",
    "                        class_names.add(class_name)\n",
    "                        samples.append((crop, SCENE2ID[class_name]))\n",
    "                        count += 1\n",
    "        if len(samples) == num_samples:\n",
    "            print(f\"Reached the limit of {num_samples} samples.\")\n",
    "            break\n",
    "       \n",
    "    print(f\"Found {len(class_names)} unique classes: {class_names} and a total of {len(samples)} samples.\")\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Saving dataset\n",
    "    labels = []\n",
    "    for idx, (image, label) in enumerate(samples):\n",
    "        image.save(os.path.join(save_path, f\"{idx}.jpg\"))\n",
    "        labels.append({\n",
    "            \"filename\": f\"{idx}.jpg\",\n",
    "            \"label\": label\n",
    "        })\n",
    "    with open(os.path.join(save_path, \"labels.json\"), 'w') as f:\n",
    "        json.dump(labels, f, indent=4)\n",
    "    print(f\"Dataset saved to {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f67e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "parition = 'val'  # or 'val', 'test'\n",
    "\n",
    "# Note: Test set of BDD-100k doesn't have annotations, so we will use the second half of validation set for testing.\n",
    "prepare_BDD(\n",
    "    image_dir=f'/scr/Pedram/VisualLearning/bdd100k/bdd100k-images/{parition}/img/',\n",
    "    label_dir=f'/scr/Pedram/VisualLearning/bdd100k/bdd100k-images/{parition}/ann/',\n",
    "    save_path=f'/scr/Pedram/VisualLearning/processed_bdd100k/{parition}',\n",
    "    input_size=224,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
